{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47af48e-a000-4afa-8123-332756cd2261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Counts:\n",
      "<s>: 3\n",
      "I: 2\n",
      "love: 2\n",
      "NLP: 1\n",
      "</s>: 3\n",
      "deep: 2\n",
      "learning: 2\n",
      "is: 1\n",
      "fun: 1\n",
      "\n",
      "Bigram Counts:\n",
      "('<s>', 'I'): 2\n",
      "('I', 'love'): 2\n",
      "('love', 'NLP'): 1\n",
      "('NLP', '</s>'): 1\n",
      "('love', 'deep'): 1\n",
      "('deep', 'learning'): 2\n",
      "('learning', '</s>'): 1\n",
      "('<s>', 'deep'): 1\n",
      "('learning', 'is'): 1\n",
      "('is', 'fun'): 1\n",
      "('fun', '</s>'): 1\n",
      "\n",
      "Sentence 1 Probability: 0.3333333333333333\n",
      "Sentence 2 Probability: 0.16666666666666666\n",
      "\n",
      "The model prefers Sentence 1 because it has higher bigram probability.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 1️⃣ Read Training Corpus\n",
    "corpus = [\n",
    "    \"<s> I love NLP </s>\",\n",
    "    \"<s> I love deep learning </s>\",\n",
    "    \"<s> deep learning is fun </s>\"\n",
    "]\n",
    "\n",
    "# 2️⃣ Compute Unigram and Bigram Counts\n",
    "unigram_counts = defaultdict(int)\n",
    "bigram_counts = defaultdict(int)\n",
    "\n",
    "for sentence in corpus:\n",
    "    words = sentence.split()\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        unigram_counts[words[i]] += 1\n",
    "        \n",
    "        if i > 0:\n",
    "            bigram = (words[i-1], words[i])\n",
    "            bigram_counts[bigram] += 1\n",
    "\n",
    "# Print counts\n",
    "print(\"Unigram Counts:\")\n",
    "for word, count in unigram_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nBigram Counts:\")\n",
    "for bigram, count in bigram_counts.items():\n",
    "    print(f\"{bigram}: {count}\")\n",
    "\n",
    "\n",
    "# 3️⃣ Estimate Bigram Probabilities (MLE)\n",
    "def bigram_probability(w1, w2):\n",
    "    return bigram_counts[(w1, w2)] / unigram_counts[w1]\n",
    "\n",
    "\n",
    "# 4️⃣ Function to Calculate Sentence Probability\n",
    "def sentence_probability(sentence):\n",
    "    words = sentence.split()\n",
    "    probability = 1.0\n",
    "    \n",
    "    for i in range(1, len(words)):\n",
    "        probability *= bigram_probability(words[i-1], words[i])\n",
    "    \n",
    "    return probability\n",
    "\n",
    "\n",
    "# 5️⃣ Test Sentences\n",
    "s1 = \"<s> I love NLP </s>\"\n",
    "s2 = \"<s> I love deep learning </s>\"\n",
    "\n",
    "p1 = sentence_probability(s1)\n",
    "p2 = sentence_probability(s2)\n",
    "\n",
    "print(\"\\nSentence 1 Probability:\", p1)\n",
    "print(\"Sentence 2 Probability:\", p2)\n",
    "\n",
    "\n",
    "# 6️⃣ Print Which Sentence is Preferred\n",
    "if p1 > p2:\n",
    "    print(\"\\nThe model prefers Sentence 1 because it has higher bigram probability.\")\n",
    "elif p2 > p1:\n",
    "    print(\"\\nThe model prefers Sentence 2 because it has higher bigram probability.\")\n",
    "else:\n",
    "    print(\"\\nBoth sentences are equally probable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06705b-c2b2-40e2-a6fd-8bd9ab94a213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
